{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Constants \n",
    "\n",
    "OUTPUT_DIR= \"OUTPUT\"\n",
    "HUB_MODULE_HANDLE = \"https://tfhub.dev/google/bert_multi_cased_L-12_H-768_A-12/1\"\n",
    "DATA_DIR = \"dataset\"\n",
    "DO_EVAL = True\n",
    "DO_TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create output directory\n",
    "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create Train Test and Validation Dataset\n",
    "df = pd.read_csv('dataset/train.tsv',sep='\\t')\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train, dev = train_test_split(train, test_size=0.2)\n",
    "\n",
    "label_list = [\"Hassan_Nisar\", \"Saleem_Safi\",\"Hamid_Mir\",\"Altaf_Hassan_Qureshi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(is_training, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  \"\"\"Creates a classification model.\"\"\"\n",
    "  tags = set()\n",
    "  if is_training:\n",
    "    tags.add(\"train\")\n",
    "  bert_module = hub.Module(\n",
    "      HUB_MODULE_HANDLE,\n",
    "      tags=tags,\n",
    "      trainable=True)\n",
    "  bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "  bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "  # In the demo, we are doing a simple classification task on the entire\n",
    "  # segment.\n",
    "  #\n",
    "  # If you want to use the token-level output, use\n",
    "  # bert_outputs[\"sequence_output\"] instead.\n",
    "  output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "  output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "  output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "  with tf.variable_scope(\"loss\"):\n",
    "    if is_training:\n",
    "      # I.e., 0.1 dropout\n",
    "      output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "\n",
    "    return (loss, per_example_loss, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps, use_tpu):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    tf.logging.info(\"*** Features ***\")\n",
    "    for name in sorted(features.keys()):\n",
    "      tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "\n",
    "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    (total_loss, per_example_loss, logits) = create_model(\n",
    "        is_training, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "    output_spec = None\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      train_op = optimization.create_optimizer(\n",
    "          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
    "\n",
    "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "          mode=mode,\n",
    "          loss=total_loss,\n",
    "          train_op=train_op)\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "\n",
    "      def metric_fn(per_example_loss, label_ids, logits):\n",
    "        predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "        accuracy = tf.metrics.accuracy(label_ids, predictions)\n",
    "        loss = tf.metrics.mean(per_example_loss)\n",
    "        return {\n",
    "            \"eval_accuracy\": accuracy,\n",
    "            \"eval_loss\": loss,\n",
    "        }\n",
    "\n",
    "      eval_metrics = (metric_fn, [per_example_loss, label_ids, logits])\n",
    "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "          mode=mode,\n",
    "          loss=total_loss,\n",
    "          eval_metrics=eval_metrics)\n",
    "    else:\n",
    "      raise ValueError(\"Only TRAIN and EVAL modes are supported: %s\" % (mode))\n",
    "\n",
    "    return output_spec\n",
    "\n",
    "  return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create tokenizer function\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(HUB_MODULE_HANDLE)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "  return tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = create_tokenizer_from_hub_module()\n",
    "\n",
    "tpu_cluster_resolver = None\n",
    "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "  cluster=tpu_cluster_resolver,\n",
    "  master=FLAGS.master,\n",
    "  model_dir=OUTPUT_DIR,\n",
    "  save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n",
    "  tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "      iterations_per_loop=FLAGS.iterations_per_loop,\n",
    "      num_shards=FLAGS.num_tpu_cores,\n",
    "      per_host_input_for_training=is_per_host))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_examples = None\n",
    "num_train_steps = None\n",
    "num_warmup_steps = None\n",
    "\n",
    "\n",
    "# Training Starts Here\n",
    "train_examples = train\n",
    "num_train_steps = int(\n",
    "    len(train_examples) / FLAGS.train_batch_size * FLAGS.num_train_epochs)\n",
    "num_warmup_steps = int(num_train_steps * FLAGS.warmup_proportion)\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=FLAGS.learning_rate,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps,\n",
    "  use_tpu=FLAGS.use_tpu)\n",
    "\n",
    "# If TPU is not available, this will fall back to normal Estimator on CPU\n",
    "# or GPU.\n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "  use_tpu=FLAGS.use_tpu,\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  train_batch_size=FLAGS.train_batch_size,\n",
    "  eval_batch_size=FLAGS.eval_batch_size)\n",
    "\n",
    "train_features = run_classifier.convert_examples_to_features(\n",
    "    train_examples, label_list, FLAGS.max_seq_length, tokenizer)\n",
    "tf.logging.info(\"***** Running training *****\")\n",
    "tf.logging.info(\"  Num examples = %d\", len(train_examples))\n",
    "tf.logging.info(\"  Batch size = %d\", FLAGS.train_batch_size)\n",
    "tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
    "train_input_fn = run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=FLAGS.max_seq_length,\n",
    "    is_training=True,\n",
    "    drop_remainder=True)\n",
    "\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_examples = dev\n",
    "eval_features = run_classifier.convert_examples_to_features(\n",
    "    eval_examples, label_list, FLAGS.max_seq_length, tokenizer)\n",
    "\n",
    "tf.logging.info(\"***** Running evaluation *****\")\n",
    "tf.logging.info(\"  Num examples = %d\", len(eval_examples))\n",
    "tf.logging.info(\"  Batch size = %d\", FLAGS.eval_batch_size)\n",
    "\n",
    "# This tells the estimator to run through the entire set.\n",
    "eval_steps = None\n",
    "\n",
    "eval_drop_remainder = True if FLAGS.use_tpu else False\n",
    "eval_input_fn = run_classifier.input_fn_builder(\n",
    "    features=eval_features,\n",
    "    seq_length=FLAGS.max_seq_length,\n",
    "    is_training=False,\n",
    "    drop_remainder=eval_drop_remainder)\n",
    "\n",
    "result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
    "\n",
    "output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
    "with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
    "  tf.logging.info(\"***** Eval results *****\")\n",
    "  for key in sorted(result.keys()):\n",
    "    tf.logging.info(\"  %s = %s\", key, str(result[key]))\n",
    "    writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}